<br> 
<center><img src="http://i.imgur.com/sSaOozN.png" width="500"></center>


## Course: VISUAL ANALYTICS FOR POLICY AND MANAGEMENT

### Prof. José Manuel Magallanes, PhD 
* Visiting Professor of Computational Policy at Evans School of Public Policy and Governance, and eScience Institute Senior Data Science Fellow, University of Washington.
* Professor of Government and Political Methodology, Pontificia Universidad Católica del Perú. 


_____


# Tabular data - Bivariate relationships III: Numerical-Numerical


Let's keep using the same data on crimes in Seattle:

```{r collect, eval=TRUE}
# collecting the data
link="https://github.com/EvansDataScience/data/raw/master/crime.RData"
load(file = url(link))
```

...and review the data:

```{r, eval=TRUE}
str(crime)
```

Let's use:

* "Occurred.Date"              
* "year"
* "month"                      
* "weekday" 
* "Reported.Date"              
* "DaysToReport"               
* "crimecat"                    
* "Neighborhood"   


```{r, eval=TRUE}
# just keeping the above vars:
varsProject=c("Occurred.Date","year", "month", "weekday", "Reported.Date" , "DaysToReport","crimecat","Neighborhood")
crime=crime[,varsProject]
crime=crime[complete.cases(crime),]
row.names(crime)=NULL
```

## Numeric-Time data

Time belongs to the interval scale. The zero does not mean absence of time, and the multiplicative interpretations do not make sense (4 pm is not twice 2 pm). I have a date variable in this data set:

```{r, eval=TRUE}
summary(crime$Occurred.Date)
```


This time, I will change the information for the *DUI* from 1908, and modified other cells as needed. First let me find out the location of that row:

```{r, eval=TRUE}
crime[which.min(crime$Occurred.Date),]
```

Then, I make the more likely real values:

```{r, eval=TRUE}
# change Date (keep format):
crime[6739,'Occurred.Date']=as.Date('2008-12-13')
# change column year:
crime[6739,'year']=2008
```

The previous changes were easy, but I need to make changes in computed fields:
```{r, eval=TRUE}
#for recomputing fields:
library(lubridate)
library(magrittr) # to use "%>%"

#change the DAY of the week
crime[6739,'weekday']=wday(as.Date('2008-12-13'), 
                           label=TRUE,
                           abbr = FALSE)

#change the period:

crime[6739,'DaysToReport']=difftime(crime[6739,'Reported.Date'],
                                    crime[6739,'Occurred.Date'],
                                    units = "days")%>%as.numeric()
```

So far, we have always prepared a frequency table when we need to plot bars. But it is also possible to request a bar plot without doing that:

```{r, eval=TRUE}
# how many crimes are occurring per day 
library(ggplot2)
base=ggplot(crime,aes(x = floor_date(Occurred.Date, "day")))
bars= base + geom_bar() 
bars
```

However, It is pretty common the use of lines. Let me prepare a line plot from our data:

```{r, eval=TRUE}
crimeDate=as.data.frame(table(crime$Occurred.Date))  # date will be a factor
head(crimeDate,10)
```

Let's change the factor to date:

```{r, eval=TRUE}
names(crimeDate)=c("date",'count')
#formatting column in Freq Table:
crimeDate$date=as.Date(crimeDate$date)

```

So now you have:

```{r, eval=TRUE}
head(crimeDate)
```

Let's get our lines:

```{r, eval=TRUE}
base=ggplot(crimeDate,
            aes(x=date,y=count))
base  + geom_line(alpha=0.3) 
```

Let's keep the data since 2010:

```{r, eval=TRUE}

base=ggplot(crimeDate[crimeDate$date>as.Date("2010-1-1"),],
            aes(x=date,y=count))
base  + geom_line(alpha=0.3) 
```


The same, but changing limits of x-axis instead of subsetting:
```{r, eval=TRUE}
min <- as.Date("2010-1-1")
max <- NA
base=ggplot(crimeDate,
            aes(x=date,y=count))
base  + geom_line(alpha=0.3) + scale_x_date(limits = c(min, max)) 
```

Counting per month:

```{r, eval=TRUE}
min <- as.Date("2010-1-1")
max <- NA
base=ggplot(crimeDate,
            aes(x=floor_date(date, "month"),
                y=count))
monthly= base  + geom_line(alpha=0.3) 
monthly= monthly + scale_x_date(limits = c(min, max))

# adding a trend:
monthly = monthly + stat_smooth(color = "red",
                      fill = "yellow",
                      method = "loess")
monthly
```

What about faceting by crime? However, our crimeDate data frame does not have that information. Let's redo it:

```{r, eval=TRUE}
crimeDate2=as.data.frame(table(crime$Occurred.Date,crime$crimecat))  # date will be a factor
head(crimeDate2,10)
```

Let's reformat crimeDate:

```{r, eval=TRUE}
names(crimeDate2)=c("date","crime",'count')
#formatting column in Freq Table:
crimeDate2$date=as.Date(crimeDate2$date)

```


```{r, eval=TRUE}
min <- as.Date("2010-1-1")
max <- NA
base=ggplot(crimeDate2,
            aes(x=floor_date(date, "month"),
                y=count))
monthly= base  + geom_line(alpha=0.3) 
monthly= monthly + scale_x_date(limits = c(min, max))

# adding a trend:
monthly = monthly + stat_smooth(color = "red",
                      fill = "yellow",
                      method = "loess")
monthly + facet_wrap(~crime)
```

Alternatively,

```{r, eval=TRUE}
monthly + facet_wrap(~reorder(crime,-count))
```

We just reorganized the previous plot so that we highlight the most and least common crimes along that time period.

So far, lines have been used to report counts of the crimes. We can also analyze the distribution of the counts using histograms. I mean:

```{r, eval=TRUE}
crime2010since=crime[crime$Occurred.Date>"2010-1-1",]
crimeTotalCountsDay=as.data.frame(table(crime2010since$Occurred.Date))
crimeTotalCountsDay$Var1=as.Date(crimeTotalCountsDay$Var1)
names(crimeTotalCountsDay)=c('date','counts')
ggplot(data=crimeTotalCountsDay, aes(x=counts)) + geom_histogram() + xlab("crime per day")
```

The plot above shows a distribution of crimes per day since 2010. Check this summary:
```{r, eval=TRUE}
summary(crimeTotalCountsDay$counts)
```
This is telling that you had a day when there were 196 crimes:
```{r, eval=TRUE}
# checking the original data:
sort(table(crime2010since$Occurred.Date),decreasing = T)[1:3]
```
```{r, eval=TRUE}
# checking the  data frame:
crimeTotalCountsDay[which.max(crimeTotalCountsDay$counts),]
```

From the summary you also know that since 2010, you can expect at least 43 crimes per day, or that the mean number of crimes per day is 126. Let's see a distribution per year:

```{r, eval=TRUE}
tapply(crimeTotalCountsDay$counts,
       year(crimeTotalCountsDay$date), FUN=summary)
```

If you need to plot this information, we need to add the column with year to the frequency table *crimeTotalCountsDay*:

```{r, eval=TRUE}
crimeTotalCountsDay$year=year(crimeTotalCountsDay$date)
#you have
head(crimeTotalCountsDay,15)
```

Now, you can plot by year:

```{r, eval=TRUE}
base = ggplot(crimeTotalCountsDay,
       aes(x = counts)) + theme_classic()
densePlot=base + geom_density(fill='grey', color=NA) 
densePlot=densePlot+ facet_wrap(~year,
                                ncol = 1, #all in one column
                                strip.position = 'right')#,#year
densePlot 

```

You can improve this with:

```{r, eval=TRUE}
densePlot + 
        # reduce space between density plot
  theme(panel.spacing.y = unit(0.1, "lines"),
        # no title on y
        axis.title.y = element_blank(),
        # no text on y
        axis.text.y = element_blank(),
        # no line on y
        axis.line.y = element_blank(),
        # no ticks on y
        axis.ticks.y = element_blank(),
        # the border and background of each year in facet:
        strip.background = element_rect(colour="white"),
        # the text of each year in facet
        strip.text.y = element_text(size=12,
                                    color="grey",
                                    angle = 0))
```

We can also use similar plots to the ones used in the previous material (cat-num). Let's keep duration longer than a year, and after 2000:

```{r filterexploreBOX2, eval=TRUE}
# new filtered data frame
crimeY2000=crime[crime$year>=2000 & crime$DaysToReport>=365,]

# create new variable in YEARS:
crimeY2000$YearsToReport=crimeY2000$DaysToReport/365
```

```{r, eval=TRUE}
#boxplot by Year
base=ggplot(data = crimeY2000,
            aes(x=as.factor(year),
                y=YearsToReport)) # is not ONE value
boxByYear=base + geom_boxplot()

boxByYear
```


Remember that although the boxplot is very informative, I recommend the use of familiar  statistics :


```{r, eval=TRUE}
# vector of colors named as stats:
myFunCols=c(Max='black',Min='blue',Median='purple')

# plotting
baseINV=ggplot(crimeY2000, aes(x=as.factor(year),
                             y=YearsToReport)) +
        theme_classic()
# points with AESthetics:
MINs=baseINV + geom_point(stat="summary",fun='max',
                          aes(color="Max")) 
MAXMINs=MINs + geom_point(stat="summary",fun='min',
                          aes(color="Min")) 
MxMnMDs=MAXMINs+ geom_point(stat="summary",fun='median',
                            aes(color="Median")) 
MxMnMDs= MxMnMDs + scale_colour_manual(values=myFunCols,
                                       name="Stats") 
MxMnMDs
```

Notice that if we want to connect the points this may not be what you have in mind:

```{r, eval=TRUE}
MxMnMDs + geom_line()

```

Remember that _YearsToReport_ is NOT one value, but several. Then, connecting the dots requires to override the grouping of the dots, to choose only ONE value, that just pick the max value:

```{r, eval=TRUE}
MxMnMDsL=MxMnMDs+ geom_line(stat="summary",fun='max',
                            aes(color="Max"),
                            group=1)
MxMnMDsL=MxMnMDsL+ geom_line(stat="summary",fun='min',
                            aes(color="Min"),
                            group=1)
MxMnMDsL=MxMnMDsL+ geom_line(stat="summary",fun='median',
                            aes(color="Median"),
                            group=1) 
MxMnMDsL + theme(axis.text.x = element_text(angle = 60,
                                            vjust = 0.5
                                            ))
```

## Numeric-Numeric data

The study of bivariate relationships among numerical variables is known as correlation analysis. The data we have been using has few numerical columns, but I will produce two by aggregating the original data since 2015 by _Neigborhood_:

* Aggregating days to report and neighborhood:
```{r aggregate, eval=TRUE}
crime2015=crime[crime$year>=2015,]
# 1. MEAN of days it takes to report a crime by neighborhood
daysByNeigh=aggregate(data=crime2015,DaysToReport~Neighborhood,mean)

# you have:
head(daysByNeigh)
```

* Aggregating crimes by neighborhood
```{r, eval=TRUE}
# 2. Crimes by neighborhood
crimesByNeigh=as.data.frame(100*prop.table(table(crime2015$Neighborhood)))
names(crimesByNeigh)=c('Neighborhood', 'CrimeShare')
head(crimesByNeigh)
```


Since both data frames have the same neighboorhood, we can make one data frame by merging them:

```{r mergeDFS, eval=TRUE}
num_num=merge(daysByNeigh,crimesByNeigh) # 'Neighborhood' is the "key"
#check after merge:
str(num_num)
```
Let's turn the _Neighborhood_ into characters:
```{r, eval=TRUE}
num_num$Neighborhood=as.character(num_num$Neighborhood)
```


Once we have the data organized, the clear option is the scatterplot:

```{r scatter, eval=TRUE}
 
base = ggplot(num_num, aes(x=DaysToReport,y=CrimeShare)) 
plot1= base +  geom_point() 
plot1
```

If you compute the Pearson correlation coefficient, you may not find a relevant correlation interesting:
```{r, eval=TRUE}
cor.test(num_num$DaysToReport,num_num$CrimeShare,method = "pearson")
```

However, you can visually find something relevant. Let's use **ggrepel** to show labels:

```{r ggscatter, eval=TRUE}
library(ggrepel)
plot1 + geom_text_repel(aes(label=Neighborhood),size=2)
```

Now we can limit the labels, annotating the ones that represent at least 5% of the crimes in the city:

```{r, eval=TRUE}
plot1 + geom_text_repel(aes(label=ifelse(CrimeShare>=5,Neighborhood, "")))
```

Or the ones that take longer than a week to report:

```{r, eval=TRUE}
plot1 + geom_text_repel(aes(label=ifelse(DaysToReport>7,Neighborhood, "")))
```


Besides conditionally annotating the places, you can identify the area of the most salient behavior. Let's highlight overlaping points:

```{r hexbins, eval=TRUE}
scatp1 = base +  geom_hex(bins = 10)
scatp2= scatp1 + geom_text_repel(aes(label=ifelse(CrimeShare>=5, Neighborhood, "")))
scatp2 + scale_fill_distiller(palette ="Greys",direction=1) # try -1
```

The palettes can be selected from the [brewer colors website](http://colorbrewer2.org). Using the same palette as before, we can try a different plot (stat_density_2d):

```{r density,eval=TRUE}
base = ggplot(num_num, aes(x=DaysToReport,y=CrimeShare)) 
scatp1 = base +  stat_density_2d(aes(fill = ..density..), 
                                 geom = "raster", contour = FALSE)
scatp2=scatp1 + geom_text_repel(aes(label=ifelse(CrimeShare>=5,
                                         Neighborhood, "")))
scatp3 = scatp2 +  theme(legend.position='none') 
scatp4= scatp3 + scale_fill_distiller(palette="Greys", direction=1) 
scatp4 
```

The extra space you see can dissappear using:

```{r, eval=TRUE}
scatp5 = scatp4 +  scale_x_continuous(breaks = c(1:20),expand = c(0, 0)) + 
         scale_y_continuous(breaks = c(1:10),expand = c(0, 0)) 
scatp5
```

Now you have an approximate of the places representing the most common behavior:

```{r, eval=TRUE}
base = ggplot(num_num, aes(x=DaysToReport,y=CrimeShare)) 
plot1= base +  geom_point() + xlim(c(2,5))+ ylim(c(0,3))
plot1 + geom_text_repel(aes(label=Neighborhood),size=2)
```

